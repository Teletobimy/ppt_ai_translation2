# translate_ppt.py  (ÏÑúÏãù Î≥¥Ï°¥ + ÌÜ§ ÏÑ†ÌÉù Î≤ÑÏ†Ñ)
# pyinstaller --onefile --name BNK_TranslatePPT PPT_Language_Change.py
import os
import re
import time
from pptx import Presentation
from pptx.dml.color import RGBColor
from pptx.enum.shapes import MSO_SHAPE_TYPE
import openai


# ---------- [ÏÑúÏãù Î≥¥Ï°¥ÏùÑ ÏúÑÌïú ÌÉúÍπÖ/Î≥µÏõê Ïú†Ìã∏] ----------
RUN_TAG = re.compile(r"\[\[R(\d+)\]\]|\[\[/R(\d+)\]\]")
P_TAG = re.compile(r"\[\[P(\d+)\]\]|\[\[/P(\d+)\]\]")
# ==== [ÏÑ§Ï†ï] =====================================================
# Îß® ÏúÑ import Í∑ºÏ≤ò
SORRY_PATTERNS = [
    "i'm sorry", "i am sorry", "sorry, but", "apologize",
    "Ï£ÑÏÜ°ÌïòÏßÄÎßå", "Ï£ÑÏÜ°Ìï©ÎãàÎã§", "Î≤àÏó≠Ìï† ÎÇ¥Ïö©Ïù¥ ÏóÜÏäµÎãàÎã§"
]

def is_effectively_empty_tagged(tagged_text: str) -> bool:
    """[[R#]]ÎßàÏª§Î•º Ï†úÍ±∞ÌïòÍ≥† ÎÇ®Îäî ÏΩòÌÖêÏ∏†Í∞Ä Ïã§ÏßàÏ†ÅÏúºÎ°ú ÎπÑÏóàÎäîÏßÄ ÌåêÎã®"""
    stripped = RUN_TAG.sub("", tagged_text)  # ÎßàÏª§ Ï†úÍ±∞
    return stripped.strip() == ""  # Í≥µÎ∞±Îßå ÎÇ®ÏúºÎ©¥ Îπà Í≤ÉÏúºÎ°ú Í∞ÑÏ£º

def looks_like_apology(text: str) -> bool:
    low = (text or "").lower()
    return any(p in low for p in SORRY_PATTERNS)

# NOTE: API keys are no longer embedded. Provide them via environment variables:
# - OPENAI_API_KEY
# - DEEPSEEK_API_KEY (optional, for DeepSeek usage)

LANG_OPTIONS = [
    "English",
    "Indonesian",
    "Italian",
    "French",
    "Spanish",
    "Korean",
    "Japanese",
    "Russian",
    "German",
    "Portuguese",
    "Chinese (Simplified)",
    "Chinese (Traditional)",
]

# ‚úÖ ÌÜ§ ÏòµÏÖò Ï∂îÍ∞Ä
TONE_OPTIONS = [
    "Í∏∞Î≥∏Í∞í",
    "Med/Pharma Pro (20y)",   # ÏùòÎ£åÍ∏∞Í∏∞/Ï†ÑÎ¨∏ÏïΩÏÇ¨ 20ÎÖÑ Ï†ÑÎ¨∏Í∞Ä
    "Beauty Pro (20y, chic)", # ÏÑ∏Î†®Îêú Î∑∞Ìã∞ 20ÎÖÑ Ï†ÑÎ¨∏Í∞Ä
    "GenZ Female (20s)",      # 20ÎåÄ Ïó¨ÏÑ± ÌÉÄÍπÉ
]

OPENAI_MODEL = "gpt-4o"
DEEPSEEK_MODEL = "deepseek-chat"
SLEEP_SEC = 0
# ===============================================================


def unique_path(path: str) -> str:  
    if not os.path.exists(path):
        return path
    base, ext = os.path.splitext(path)
    i = 1
    while True:
        candidate = f"{base} ({i}){ext}"
        if not os.path.exists(candidate):
            return candidate
        i += 1

def create_deepseek_client():
    """DeepSeek ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ±"""
    api_key = os.getenv("DEEPSEEK_API_KEY", "")
    if not api_key:
        raise RuntimeError("DEEPSEEK_API_KEY is not set. Configure it in secrets or environment.")
    return openai.OpenAI(api_key=api_key, base_url="https://api.deepseek.com")


def safe_request(client, prompt, retries=3, delay=3, use_deepseek=False):
    for attempt in range(retries):
        try:
            model = DEEPSEEK_MODEL if use_deepseek else OPENAI_MODEL
            resp = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                timeout=60,
            )
            content = ""
            if resp and hasattr(resp, "choices") and resp.choices:
                content = getattr(resp.choices[0].message, "content", "") or ""
            if content:
                return content.strip()
        except Exception as e:
            print(f"‚ö†Ô∏è Error (attempt {attempt+1}): {e}")
            with open("error.log", "a", encoding="utf-8") as f:
                f.write(f"[Attempt {attempt+1}] {e}\n")
            time.sleep(delay)
    return ""




def _font_attrs(run):
    f = run.font
    # Í∞í Í∑∏ÎåÄÎ°ú Î≥¥Ï°¥(None Ìè¨Ìï®)
    name = f.name                 # NoneÏù¥Î©¥ ÌÖåÎßà/ÎßàÏä§ÌÑ∞ ÏÉÅÏÜç
    size = f.size.pt if f.size else None
    bold = f.bold                 # True/False/None
    italic = f.italic             # True/False/None
    underline = f.underline       # True/False/None

    rgb = None
    if f.color is not None and getattr(f.color, "rgb", None) is not None:
        rgb = (f.color.rgb[0], f.color.rgb[1], f.color.rgb[2])

    return {"name": name, "size": size, "bold": bold, "italic": italic,
            "underline": underline, "rgb": rgb}

def _apply_font_attrs(run, attrs):
    from pptx.util import Pt
    f = run.font

    if attrs.get("name") is not None:
        f.name = attrs["name"]
    if attrs.get("size") is not None:
        f.size = Pt(attrs["size"])
    if attrs.get("bold") is not None:
        f.bold = attrs["bold"]
    if attrs.get("italic") is not None:
        f.italic = attrs["italic"]
    if attrs.get("underline") is not None:
        f.underline = attrs["underline"]
    if attrs.get("rgb") is not None:
        r, g, b = attrs["rgb"]
        f.color.rgb = RGBColor(r, g, b)


def tag_paragraph(paragraph):
    text_parts, style_map, idx = [], {}, 1
    for run in paragraph.runs:
        t = run.text or ""
        if not t:
            continue
        style_map[idx] = _font_attrs(run)
        text_parts.append(f"[[R{idx}]]{t}[[/R{idx}]]")
        idx += 1
    return "".join(text_parts), style_map

def rebuild_paragraph_from_tagged(paragraph, translated, style_map):
    while paragraph.runs:
        paragraph.runs[0]._r.getparent().remove(paragraph.runs[0]._r)

    tokens, pos = [], 0
    for m in RUN_TAG.finditer(translated):
        s, e = m.span()
        if s > pos:
            tokens.append(("text", translated[pos:s]))
        if m.group(1):
            tokens.append(("start", int(m.group(1))))
        if m.group(2):
            tokens.append(("end", int(m.group(2))))
        pos = e
    if pos < len(translated):
        tokens.append(("text", translated[pos:]))

    out_runs, stack, buffer = [], [], {}
    for ttype, value in tokens:
        if ttype == "start":
            stack.append(value)
            buffer.setdefault(value, [])
        elif ttype == "end":
            if stack and stack[-1] == value:
                stack.pop()
            joined = "".join(buffer.get(value, []))
            out_runs.append((value, joined))
            buffer[value] = []
        else:
            if stack:
                buffer[stack[-1]].append(value)
            else:
                out_runs.append((None, value))

    for run_id, buf in buffer.items():
        if buf:
            out_runs.append((run_id, "".join(buf)))

    if not out_runs:
        r = paragraph.add_run()
        r.text = translated
        return

    for run_id, txt in out_runs:
        if not txt:
            continue
        r = paragraph.add_run()
        r.text = txt
        if run_id and run_id in style_map:
            _apply_font_attrs(r, style_map[run_id])

def _parse_run_chunks(translated):
    # R# ‚Üí ÌÖçÏä§Ìä∏ Îß§ÌïëÍ≥º, ÎßàÏª§ Î∞ñ ÌÖçÏä§Ìä∏ Ï°¥Ïû¨ Ïó¨Î∂ÄÎ•º ÌåêÏ†ï
    ids = []
    chunks = {}
    stack = []
    buf = {}
    outside = []

    pos = 0
    for m in RUN_TAG.finditer(translated):
        s, e = m.span()
        if s > pos:
            if stack:
                buf.setdefault(stack[-1], []).append(translated[pos:s])
            else:
                outside.append(translated[pos:s])
        if m.group(1):  # [[R#]]
            rid = int(m.group(1)); stack.append(rid); ids.append(rid)
        if m.group(2):  # [[/R#]]
            rid = int(m.group(2))
            if stack and stack[-1] == rid:
                stack.pop()
                joined = "".join(buf.get(rid, []))
                chunks[rid] = joined
                buf[rid] = []
        pos = e
    if pos < len(translated):
        if stack:
            buf.setdefault(stack[-1], []).append(translated[pos:])
        else:
            outside.append(translated[pos:])

    # Îã´ÌûàÏßÄ ÏïäÏùÄ Î≤ÑÌçº Ï≤òÎ¶¨
    for rid, lst in buf.items():
        if lst:
            chunks[rid] = chunks.get(rid, "") + "".join(lst)

    has_outside = any(t.strip() for t in outside)
    return ids, chunks, has_outside

def try_inplace_update_paragraph(paragraph, translated):
    """ÎßàÏª§Í∞Ä 1..NÏúºÎ°ú Ï†ïÌôïÌûà Ï°¥Ïû¨ÌïòÍ≥†, ÎßàÏª§ Î∞ñ ÌÖçÏä§Ìä∏Í∞Ä ÏóÜÏúºÎ©¥
    Í∏∞Ï°¥ runsÏóê ÌÖçÏä§Ìä∏Îßå Ï£ºÏûÖÌïòÏó¨ ÏÑúÏãùÏùÑ 100% Ïú†ÏßÄÌïúÎã§."""
    ids, chunks, has_outside = _parse_run_chunks(translated)
    runs = [r for r in paragraph.runs if (r.text or "") != ""]
    N = len(runs)

    # Ï°∞Í±¥: ÎßàÏª§ Î∞ñ ÌÖçÏä§Ìä∏Í∞Ä ÏóÜÏñ¥Ïïº ÌïòÍ≥†, R1..RNÏù¥ Ï†ïÌôïÌûà Ìïú Î≤àÏî© Ï°¥Ïû¨
    if has_outside or N == 0 or set(ids) != set(range(1, N+1)) or any(ids.count(i) != 1 for i in range(1, N+1)):
        return False

    for i, run in enumerate(runs, start=1):
        run.text = chunks.get(i, "")
    return True


# ---------- [ÌîÑÎ°¨ÌîÑÌä∏ ÎπåÎçî] ----------
def build_tone_instructions(tone: str) -> str:
    """
    ÏÑ†ÌÉùÌïú ÌÜ§Ïóê ÎßûÎäî ÏßÄÏãúÎ¨∏ÏùÑ Î∞òÌôò
    """
    if tone == "Í∏∞Î≥∏Í∞í":
        return (
            "Use a natural, professional beauty-industry tone localized to the target market. "
            "Keep terminology consistent with beauty marketing and professional skincare. "
            "Be clear and persuasive without hype; avoid overpromising."
        )
    if tone == "Med/Pharma Pro (20y)":
        return (
            "Use a formal, clinically precise B2B tone suitable for medical devices and professional pharmacists. "
            "Prioritize clarity, compliance, and evidence-based wording. Avoid hype. "
            "Prefer terminology used in regulatory, clinical, and professional settings."
        )
    if tone == "Beauty Pro (20y, chic)":
        return (
            "Use a refined, polished professional tone common in premium beauty and aesthetic clinics. "
            "Balance expertise with approachable elegance. Maintain brand voice consistency without overpromising."
        )
    if tone == "GenZ Female (20s)":
        return (
            "Use a modern, friendly, and concise tone tailored for women in their 20s. "
            "Be clear and engaging for social content, but avoid slang overload, emojis, and exaggerated claims."
        )
    # fallback
    return "Use a neutral professional tone appropriate for the beauty industry."

def build_chinese_prompt(tagged_text: str, target_lang: str) -> str:
    """
    Ï†ÑÎ¨∏Ï†ÅÏù∏ ÌïúÍµ≠Ïñ¥‚ÜíÏ§ëÍµ≠Ïñ¥ Î≤àÏó≠ÏùÑ ÏúÑÌïú ÌîÑÎ°¨ÌîÑÌä∏ (Í∞ÑÏ≤¥/Î≤àÏ≤¥ Íµ¨Î∂Ñ)
    """
    chinese_type = "Í∞ÑÏ≤¥" if "Simplified" in target_lang else "Î≤àÏ≤¥"
    
    return (
        f"ÎãπÏã†ÏùÄ ÌïúÍµ≠Ïñ¥Î•º Ï†ïÌôïÌïòÍ≥† ÏûêÏó∞Ïä§Îü¨Ïö¥ Ï§ëÍµ≠Ïñ¥({chinese_type})Î°ú Î≤àÏó≠ÌïòÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.\n\n"
        f"# Ï£ºÏöî ÌäπÏßï\n"
        f"- ÌîÑÎ†àÏ††ÌÖåÏù¥ÏÖò, Î≥¥Í≥†ÏÑú, ÎπÑÏ¶àÎãàÏä§ Î¨∏ÏÑú Îì±Ïóê Ï†ÅÌï©Ìïú Í≥µÏãùÏ†ÅÏù¥Í≥† ÏÑ∏Î†®Îêú ÌëúÌòÑ ÏÇ¨Ïö©\n"
        f"- Î¨∏Îß•ÏùÑ Í≥†Î†§ÌïòÏó¨ Î¨∏Ïû•Ïùò ÏùòÎØ∏ÏôÄ ÎâòÏïôÏä§Î•º ÏÑ∏Î∞ÄÌïòÍ≤å Î∂ÑÏÑùÌïòÏó¨ Ï†ÅÏ†àÌïú ÌëúÌòÑÏúºÎ°ú Î≤àÏó≠\n"
        f"- ÏõêÎ¨∏Ïùò ÏùòÎèÑÏôÄ Ïñ¥Ï°∞Î•º Ïú†ÏßÄÌïòÎêò, Ï§ëÍµ≠ ÏõêÏñ¥ÎØºÏù¥ ÏûêÏó∞Ïä§ÎüΩÍ≤å Îì§Î¶¨ÎèÑÎ°ù Î¨∏Ïû• Íµ¨Ï°∞ Ï°∞Ï†ï\n"
        f"- Î≤àÏó≠ Ïù¥Ïô∏Ïùò Î∂àÌïÑÏöîÌïú ÏÑ§Î™Ö Í∏àÏßÄ\n"
        f"- Ï∞ΩÏùòÏ†Å Ïû¨Ìï¥ÏÑù ÏóÜÏù¥ ÏõêÎ¨∏Ïóê Ï∂©Ïã§Ìïú Î≤àÏó≠ ÏàòÌñâ\n"
        f"- Î∞òÎìúÏãú Ï§ëÍµ≠Ïñ¥ {chinese_type}Î°ú Î≤àÏó≠ÌïòÏÑ∏Ïöî\n\n"
        f"# Í≥†Ïú†Î™ÖÏÇ¨ Ï≤òÎ¶¨ Í∑úÏπô\n"
        f"- 'ÌîºÎçîÎ¶∞'ÏùÄ 'PYDERIN'ÏúºÎ°ú Î≤àÏó≠ÌïòÏÑ∏Ïöî (Î∏åÎûúÎìúÎ™ÖÏù¥ÎØÄÎ°ú ÎåÄÎ¨∏ÏûêÎ°ú)\n"
        f"- Í∏∞ÌÉÄ Í≥†Ïú†Î™ÖÏÇ¨(Ïù∏Î™Ö, ÏßÄÎ™Ö, ÌöåÏÇ¨Î™Ö, Î∏åÎûúÎìúÎ™Ö Îì±)Îäî Î≤àÏó≠ÌïòÏßÄ ÎßêÍ≥† ÏõêÎ¨∏ Í∑∏ÎåÄÎ°ú Ïú†ÏßÄÌïòÏÑ∏Ïöî\n"
        f"- ÏòÅÏñ¥ Í≥†Ïú†Î™ÖÏÇ¨Îäî Í∑∏ÎåÄÎ°ú Ïú†ÏßÄÌïòÏÑ∏Ïöî\n\n"
        f"Îã§Ïùå ÌïúÍµ≠Ïñ¥ ÌÖçÏä§Ìä∏Î•º ÏûêÏó∞Ïä§Îü¨Ïö¥ Ï§ëÍµ≠Ïñ¥({chinese_type})Î°ú Î≤àÏó≠ÌïòÏÑ∏Ïöî.\n"
        f"Ï§ëÏöî: Îã®ÎùΩ ÎßàÏª§ [[P#]]...[[/P#]]ÏôÄ Îü∞ ÎßàÏª§ [[R#]]...[[/R#]]Îäî Ï†àÎåÄ Î≥ÄÍ≤ΩÌïòÍ±∞ÎÇò Ï†úÍ±∞ÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n"
        f"- Îã®ÎùΩ Í∞úÏàò(P#)ÏôÄ ÏàúÏÑúÎ•º Ï†ïÌôïÌûà Ïú†ÏßÄÌïòÏÑ∏Ïöî.\n"
        f"- ÎßàÏª§ ÎÇ¥Î∂Ä ÌÖçÏä§Ìä∏Îßå Î≤àÏó≠ÌïòÍ≥†, ÎßàÏª§ ÏûêÏ≤¥Îäî Í∑∏ÎåÄÎ°ú ÎëêÏÑ∏Ïöî.\n\n"
        f"Î≤àÏó≠Ìï† ÌÖçÏä§Ìä∏:\n{tagged_text}"
    )

def build_prompt(tagged_text: str, target_lang: str, tone: str) -> str:
    # Chinese translation uses specialized prompt
    if "Chinese" in target_lang:
        return build_chinese_prompt(tagged_text, target_lang)
    
    tone_text = build_tone_instructions(tone)
    return (
        f"Translate the following beauty industry presentation text into natural, professional {target_lang}. "
        f"Only return the translated text. If there is nothing to translate, return an empty string. "
        f"Context: {tone_text} "
        f"Avoid literal translation‚Äîuse expressions that sound natural for beauty marketing and professional skincare. "
        f"If the source is already in {target_lang}, lightly copyedit for clarity, consistency, and terminology. "
        f"CRITICAL: Do NOT alter or remove any marker tags. Preserve both paragraph markers [[P#]]...[[/P#]] and run markers [[R#]]...[[/R#]] exactly, including counts and order. "
        f"Return ONLY the translated text with all markers preserved:\n\n{tagged_text}"
    )



# ---------- [Î≤àÏó≠ Ìò∏Ï∂ú] ----------
def gpt_translate_tagged(tagged_text: str, client, target_lang: str, tone: str, use_deepseek=False) -> str:
    # ÏßÑÏßú ÎÇ¥Ïö©Ïù¥ ÏóÜÏúºÎ©¥ Î≤àÏó≠ Ïä§ÌÇµ
    if not tagged_text.strip() or is_effectively_empty_tagged(tagged_text):
        return ""

    # Ï§ëÍµ≠Ïñ¥ Î≤àÏó≠Ïùò Í≤ΩÏö∞ DeepSeek ÏÇ¨Ïö©
    if "Chinese" in target_lang and use_deepseek:
        deepseek_client = create_deepseek_client()
        prompt = build_chinese_prompt(tagged_text, target_lang)
        content = safe_request(deepseek_client, prompt, retries=3, delay=3, use_deepseek=True)
    else:
        prompt = build_prompt(tagged_text, target_lang, tone)
        content = safe_request(client, prompt, retries=3, delay=3)

    # Ïã§Ìå® Ïãú ÏõêÎ¨∏(ÎßàÏª§ Ìè¨Ìï®) Î∞òÌôò ‚Üí ÏõêÎ¨∏ Ïú†ÏßÄ
    if not content:
        return tagged_text

    # ÏÇ¨Í≥ºÎ¨∏/ÏóêÎü¨Î¨∏Íµ¨Í∞Ä Îì§Ïñ¥Ïò§Î©¥ ÏõêÎ¨∏ Ïú†ÏßÄ
    if looks_like_apology(content):
        return tagged_text

    return content

def gpt_review_chinese_translation(original_korean: str, translated_chinese: str, client, use_deepseek=False) -> dict:
    """
    Ï§ëÍµ≠Ïñ¥ Î≤àÏó≠Ïùò ÏûêÏó∞Ïä§Îü¨ÏõÄÏùÑ Í≤ÄÌÜ†ÌïòÍ≥† ÌïÑÏöîÏãú ÏàòÏ†ïÎêú Î≤àÏó≠ÏùÑ Î∞òÌôò
    """
    if not original_korean.strip() or not translated_chinese.strip():
        return {"is_awkward": False, "revised_translation": translated_chinese}
    
    review_prompt = (
        f"ÎãπÏã†ÏùÄ Ï§ëÍµ≠Ïñ¥ Î≤àÏó≠ ÌíàÏßàÏùÑ Í≤ÄÌÜ†ÌïòÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.\n\n"
        f"ÏõêÎ¨∏ (ÌïúÍµ≠Ïñ¥): {original_korean}\n"
        f"Î≤àÏó≠Î¨∏ (Ï§ëÍµ≠Ïñ¥): {translated_chinese}\n\n"
        f"Îã§ÏùåÏùÑ Í≤ÄÌÜ†Ìï¥Ï£ºÏÑ∏Ïöî:\n"
        f"1. Ï§ëÍµ≠ ÏõêÏñ¥ÎØºÏù¥ ÏùΩÏóàÏùÑ Îïå Ïñ¥ÏÉâÌïòÍ±∞ÎÇò Î∂ÄÏûêÏó∞Ïä§Îü¨Ïö¥ Î∂ÄÎ∂ÑÏù¥ ÏûàÎäîÍ∞Ä?\n"
        f"2. Î¨∏Î≤ïÏ†ÅÏúºÎ°ú Ïò¨Î∞îÎ•∏Í∞Ä?\n"
        f"3. ÌëúÌòÑÏù¥ ÏûêÏó∞Ïä§Îü¨Ïö¥Í∞Ä?\n\n"
        f"ÏùëÎãµ ÌòïÏãù:\n"
        f"Ïñ¥ÏÉâÌï®: [YES/NO]\n"
        f"ÏàòÏ†ïÎêú Î≤àÏó≠: [ÏàòÏ†ïÎêú Ï§ëÍµ≠Ïñ¥ Î≤àÏó≠ ÎòêÎäî ÏõêÎûò Î≤àÏó≠]\n"
        f"ÏÑ§Î™Ö: [Ïñ¥ÏÉâÌïú Ïù¥Ïú† ÎòêÎäî ÏàòÏ†ï ÏÇ¨Ìï≠]\n\n"
        f"Ï§ëÏöî: [[P#]]ÏôÄ [[R#]] ÎßàÏª§Îäî Ï†àÎåÄ Î≥ÄÍ≤ΩÌïòÏßÄ ÎßàÏÑ∏Ïöî."
    )
    
    try:
        if use_deepseek:
            deepseek_client = create_deepseek_client()
            content = safe_request(deepseek_client, review_prompt, retries=2, delay=2, use_deepseek=True)
        else:
            content = safe_request(client, review_prompt, retries=2, delay=2)
            
        if not content:
            return {"is_awkward": False, "revised_translation": translated_chinese}
        
        # Parse response
        lines = content.strip().split('\n')
        is_awkward = False
        revised_translation = translated_chinese
        
        for line in lines:
            if line.startswith("Ïñ¥ÏÉâÌï®:"):
                is_awkward = "YES" in line.upper()
            elif line.startswith("ÏàòÏ†ïÎêú Î≤àÏó≠:"):
                revised_translation = line.replace("ÏàòÏ†ïÎêú Î≤àÏó≠:", "").strip()
        
        return {"is_awkward": is_awkward, "revised_translation": revised_translation}
        
    except Exception as e:
        print(f"‚ö†Ô∏è Review error: {e}")
        return {"is_awkward": False, "revised_translation": translated_chinese}




# ---------- [ÌååÏùº/Ïñ∏Ïñ¥/ÌÜ§ ÏÑ†ÌÉù UI] ----------
def choose_pptx_with_dialog() -> str:
    # Lazy import Tkinter for desktop-only usage
    import tkinter as tk  # type: ignore
    from tkinter import filedialog  # type: ignore

    root = tk.Tk()
    root.withdraw()
    root.update_idletasks()
    filepath = filedialog.askopenfilename(
        title="Î≤àÏó≠Ìï† PPTX ÌååÏùº ÏÑ†ÌÉù",
        filetypes=[("PowerPoint files", "*.pptx")],
    )
    root.destroy()
    return filepath or ""

def choose_language_with_window() -> str:
    sel = {"value": ""}

    def on_start():
        v = var.get().strip()
        if not v:
            from tkinter import messagebox  # type: ignore
            messagebox.showwarning("ÏïåÎ¶º", "Ïñ∏Ïñ¥Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.")
            return
        sel["value"] = v
        win.destroy()

    import tkinter as tk  # type: ignore
    win = tk.Tk()
    win.title("Target Language")
    win.geometry("360x160")
    win.resizable(False, False)

    frm = tk.Frame(win, padx=12, pady=12)
    frm.pack(fill="both", expand=True)

    tk.Label(frm, text="Î≤àÏó≠ ÎåÄÏÉÅ Ïñ∏Ïñ¥ ÏÑ†ÌÉù:").pack(anchor="w", pady=(0, 6))

    var = tk.StringVar(value=LANG_OPTIONS[0])
    opt = tk.OptionMenu(frm, var, *LANG_OPTIONS)
    opt.pack(fill="x")

    tk.Button(frm, text="Îã§Ïùå(ÌÜ§ ÏÑ†ÌÉù)", command=on_start).pack(pady=12)

    win.lift(); win.attributes("-topmost", True); win.after(200, lambda: win.attributes("-topmost", False))
    win.mainloop()
    return sel["value"]

def choose_tone_with_window(selected_language: str) -> tuple:
    sel = {"value": "", "use_deepseek": False}

    def on_start():
        v = var.get().strip()
        if not v:
            from tkinter import messagebox  # type: ignore
            messagebox.showwarning("ÏïåÎ¶º", "ÌÜ§ÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.")
            return
        sel["value"] = v
        sel["use_deepseek"] = deepseek_var.get()
        win.destroy()

    import tkinter as tk  # type: ignore
    win = tk.Tk()
    win.title("Target Tone & DeepSeek Option")
    win.geometry("450x280")
    win.resizable(False, False)

    frm = tk.Frame(win, padx=12, pady=12)
    frm.pack(fill="both", expand=True)

    tk.Label(frm, text="Î≤àÏó≠ ÌÜ§ ÏÑ†ÌÉù:").pack(anchor="w", pady=(0, 6))

    var = tk.StringVar(value=TONE_OPTIONS[0])
    opt = tk.OptionMenu(frm, var, *TONE_OPTIONS)
    opt.pack(fill="x")

    # DeepSeek ÏÇ¨Ïö© ÏòµÏÖò (Ï§ëÍµ≠Ïñ¥Ïùº ÎïåÎßå ÌëúÏãú)
    if "Chinese" in selected_language:
        deepseek_frame = tk.Frame(frm)
        deepseek_frame.pack(fill="x", pady=(10, 0))
        
        deepseek_var = tk.BooleanVar(value=True)
        chinese_type = "Í∞ÑÏ≤¥" if "Simplified" in selected_language else "Î≤àÏ≤¥"
        deepseek_check = tk.Checkbutton(
            deepseek_frame,
            text=f"Ï§ëÍµ≠Ïñ¥({chinese_type}) Î≤àÏó≠ Ïãú DeepSeek ÏÇ¨Ïö© (Í∂åÏû•)",
            variable=deepseek_var,
            font=("Arial", 9, "bold")
        )
        deepseek_check.pack(anchor="w")
        
        deepseek_info = tk.Label(
            deepseek_frame,
            text=f"‚úì DeepSeekÏùÄ Ï§ëÍµ≠Ïñ¥({chinese_type}) Î≤àÏó≠Ïóê ÌäπÌôîÎêòÏñ¥ Îçî ÏûêÏó∞Ïä§Îü¨Ïö¥ Î≤àÏó≠ Í≤∞Í≥ºÎ•º Ï†úÍ≥µÌï©ÎãàÎã§",
            font=("Arial", 8),
            fg="blue"
        )
        deepseek_info.pack(anchor="w", pady=(2, 0))
    else:
        deepseek_var = tk.BooleanVar(value=False)

    # Í∞ÑÎã®Ìïú ÏÑ§Î™Ö ÎùºÎ≤®
    info = tk.Label(
        frm,
        justify="left",
        text=(
            "- Í∏∞Î≥∏Í∞í: ÏùºÎ∞òÎ∑∞Ìã∞ÏóÖÍ≥Ñ, ÏßÅÏó≠ ÏµúÎåÄÌïú ÌöåÌîº\n"
            "- Med/Pharma Pro: ÏùòÎ£åÍ∏∞Í∏∞/Ï†ÑÎ¨∏ÏïΩÏÇ¨ 20ÎÖÑ Ï†ÑÎ¨∏Í∞Ä ÌÜ§\n"
            "- Beauty Pro (chic): ÌîÑÎ¶¨ÎØ∏ÏóÑ Î∑∞Ìã∞ Ï†ÑÎ¨∏Í∞Ä ÌÜ§\n"
            "- GenZ Female: 20ÎåÄ Ïó¨ÏÑ± ÌÉÄÍπÉÏùò ÏπúÍ∑ºÌïú ÌÜ§(Í≥ºÏû•¬∑Ïä¨Îû≠ Í≥ºÎã§ Í∏àÏßÄ)"
        ),
    )
    info.pack(anchor="w", pady=8)

    tk.Button(frm, text="Î≤àÏó≠ ÏãúÏûë", command=on_start).pack(pady=6)

    win.lift(); win.attributes("-topmost", True); win.after(200, lambda: win.attributes("-topmost", False))
    win.mainloop()
    return sel["value"], sel["use_deepseek"]


def choose_font_scale_window() -> int:
    """Ìè∞Ìä∏ Ïä§ÏºÄÏùº(%) ÏÑ†ÌÉù Ï∞Ω. Í∏∞Î≥∏ 100."""
    sel = {"value": 100}

    def on_ok():
        try:
            v = int(entry.get().strip())
            if v < 50 or v > 300:
                from tkinter import messagebox  # type: ignore
                messagebox.showwarning("ÏïåÎ¶º", "50% ~ 300% ÏÇ¨Ïù¥Ïùò Í∞íÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî.")
                return
            sel["value"] = v
            win.destroy()
        except Exception:
            from tkinter import messagebox  # type: ignore
            messagebox.showwarning("ÏïåÎ¶º", "Ï†ïÏàò % Í∞íÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî (Ïòà: 90, 100, 120)")

    import tkinter as tk  # type: ignore
    win = tk.Tk()
    win.title("Font Scale (%)")
    win.geometry("360x160")
    win.resizable(False, False)

    frm = tk.Frame(win, padx=12, pady=12)
    frm.pack(fill="both", expand=True)

    tk.Label(frm, text="Î≤àÏó≠ ÌõÑ Ìè∞Ìä∏ ÌÅ¨Í∏∞ Î∞∞Ïú®(%)").pack(anchor="w", pady=(0, 6))

    quick = tk.Frame(frm)
    quick.pack(anchor="w", pady=(0, 6))

    def set_quick(val):
        entry.delete(0, tk.END)
        entry.insert(0, str(val))

    for val in (80, 90, 100, 110, 120, 130):
        tk.Button(quick, text=f"{val}%", command=lambda v=val: set_quick(v), width=6).pack(side="left", padx=2)

    entry = tk.Entry(frm)
    entry.insert(0, "100")
    entry.pack(fill="x")

    tk.Button(frm, text="ÌôïÏù∏", command=on_ok).pack(pady=10)

    win.lift(); win.attributes("-topmost", True); win.after(200, lambda: win.attributes("-topmost", False))
    win.mainloop()
    return sel["value"]


# ---------- [Î≥∏ Ï≤òÎ¶¨] ----------
def translate_presentation(pptx_path: str, target_lang: str, tone: str, use_deepseek=False, font_scale_percent: int = 100):
    print(f"üìÇ ÌååÏùº: {pptx_path}")
    print(f"üåê ÎåÄÏÉÅ Ïñ∏Ïñ¥: {target_lang}")
    print(f"üéô ÌÜ§: {tone}")
    if target_lang == "Chinese" and use_deepseek:
        print("ü§ñ DeepSeek Î™®Îç∏ ÏÇ¨Ïö© Ï§ë...")
    else:
        print("üîë OpenAI ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî Ï§ë...")

    # Create OpenAI client from environment (Streamlit will provide via st.secrets)
    openai_key = os.getenv("OPENAI_API_KEY", "")
    if not openai_key:
        raise RuntimeError("OPENAI_API_KEY is not set. Configure it in secrets or environment.")
    client = openai.OpenAI(api_key=openai_key)

    print("üìñ ÌîÑÎ†àÏ††ÌÖåÏù¥ÏÖò Î°úÎî©...")
    pres = Presentation(pptx_path)

    slide_count = len(pres.slides)
    print(f"üñº Ïä¨ÎùºÏù¥Îìú Ïàò: {slide_count}")
    print(f"üîç Ìè∞Ìä∏ Î∞∞Ïú®: {font_scale_percent}%")
    
    # ---------- [Î∏îÎ°ù ÌÉúÍπÖ/Ïû¨Íµ¨ÏÑ± Ïú†Ìã∏] ----------
    def tag_paragraphs_block(paragraphs):
        """Îã®ÎùΩ Îã®ÏúÑÎ°ú [[P#]] ÎûòÌïëÌïòÍ≥†, Í∞Å Îã®ÎùΩ ÎÇ¥Î∂ÄÎäî Í∏∞Ï°¥ [[R#]] ÎßàÏª§Î°ú ÌÉúÍπÖ.
        Î∞òÌôò: (block_text, per_para_style_maps)
        """
        parts = []
        style_maps = []
        para_index = 1
        has_any = False
        for p in paragraphs:
            tagged, style_map = tag_paragraph(p)
            style_maps.append(style_map)
            if tagged:
                has_any = True
            parts.append(f"[[P{para_index}]]{tagged}[[/P{para_index}]]")
            para_index += 1
        return ("".join(parts), style_maps, has_any)

    def _parse_p_blocks(translated_block: str):
        """Î∏îÎ°ù ÌÖçÏä§Ìä∏ÏóêÏÑú P ÎßàÏª§Ïóê Ìï¥ÎãπÌïòÎäî ÌÖçÏä§Ìä∏Î•º Ï∂îÏ∂ú.
        Î∞òÌôò: (ids_in_order, p_to_inner_text, has_outside)
        """
        ids = []
        p_chunks = {}
        stack = []
        buf = {}
        outside = []

        pos = 0
        for m in P_TAG.finditer(translated_block):
            s, e = m.span()
            if s > pos:
                if stack:
                    buf.setdefault(stack[-1], []).append(translated_block[pos:s])
                else:
                    outside.append(translated_block[pos:s])
            if m.group(1):  # [[P#]]
                pid = int(m.group(1)); stack.append(pid); ids.append(pid)
            if m.group(2):  # [[/P#]]
                pid = int(m.group(2))
                if stack and stack[-1] == pid:
                    stack.pop()
                    joined = "".join(buf.get(pid, []))
                    p_chunks[pid] = joined
                    buf[pid] = []
            pos = e
        if pos < len(translated_block):
            if stack:
                buf.setdefault(stack[-1], []).append(translated_block[pos:])
            else:
                outside.append(translated_block[pos:])

        for pid, lst in buf.items():
            if lst:
                p_chunks[pid] = p_chunks.get(pid, "") + "".join(lst)

        has_outside = any(t.strip() for t in outside)
        return ids, p_chunks, has_outside

    def rebuild_block_from_tagged(paragraphs, translated_block: str, style_maps):
        """P Î∏îÎ°ùÏùÑ ÌååÏã±ÌïòÏó¨ Í∞Å Îã®ÎùΩÏóê ÎåÄÌï¥ Í∏∞Ï°¥ Îü∞ÏùÑ Î≥¥Ï°¥ÌïòÎ©∞ ÌÖçÏä§Ìä∏ Ï£ºÏûÖ.
        ÎßàÏª§ ÎòêÎäî Í∞úÏàò Î∂àÏùºÏπò Ïãú False Î∞òÌôò.
        """
        ids, p_chunks, has_outside = _parse_p_blocks(translated_block)
        N = len(paragraphs)
        if has_outside or N == 0:
            return False
        # P1..PNÏù¥ Ï†ïÌôïÌûà 1ÌöåÏî© Ï°¥Ïû¨ÌïòÎäîÏßÄ
        if set(ids) != set(range(1, N+1)) or any(ids.count(i) != 1 for i in range(1, N+1)):
            return False

        for i, p in enumerate(paragraphs, start=1):
            inner = p_chunks.get(i, "")
            # Î®ºÏ†Ä Ïù∏ÌîåÎ†àÏù¥Ïä§ ÏãúÎèÑ (Îü∞ Î≥¥Ï°¥)
            if not try_inplace_update_paragraph(p, inner):
                rebuild_paragraph_from_tagged(p, inner, style_maps[i-1])
        return True
    
    print("-" * 60)

    def process_paragraphs_block(paragraphs, chinese_review_enabled=False):
        block_tagged, style_maps, has_any = tag_paragraphs_block(paragraphs)
        if not has_any:
            return  # nothing to translate
        translated_block = gpt_translate_tagged(block_tagged, client, target_lang, tone, use_deepseek)
        translated_block = translated_block.strip().strip('"').strip("'")
        if chinese_review_enabled:
            review_result = gpt_review_chinese_translation(block_tagged, translated_block, client, use_deepseek)
            if review_result.get("is_awkward"):
                translated_block = review_result.get("revised_translation", translated_block)
                chinese_type = "Í∞ÑÏ≤¥" if "Simplified" in target_lang else "Î≤àÏ≤¥"
                print(f"   ‚úÖ Ïñ¥ÏÉâÌïú Î≤àÏó≠ Í∞êÏßÄ (Î∏îÎ°ù, Ï§ëÍµ≠Ïñ¥ {chinese_type}) - ÏàòÏ†ïÎê®")
        # Ïö∞ÏÑ† Î∏îÎ°ù Îã®ÏúÑ Î≥µÏõê ÏãúÎèÑ
        if not rebuild_block_from_tagged(paragraphs, translated_block, style_maps):
            # P ÎßàÏª§ Î∂àÏùºÏπò ‚Üí Îã®ÎùΩ Îã®ÏúÑÎ°ú Ìè¥Î∞±
            for p in paragraphs:
                tagged, style_map = tag_paragraph(p)
                if not tagged:
                    continue
                t = gpt_translate_tagged(tagged, client, target_lang, tone, use_deepseek)
                t = t.strip().strip('"').strip("'")
                if chinese_review_enabled:
                    rr = gpt_review_chinese_translation(tagged, t, client, use_deepseek)
                    if rr.get("is_awkward"):
                        t = rr.get("revised_translation", t)
                if not try_inplace_update_paragraph(p, t):
                    rebuild_paragraph_from_tagged(p, t, style_map)
                time.sleep(SLEEP_SEC)

    def traverse_shape(shape):
        # Í∑∏Î£π: Ïû¨Í∑Ä
        if getattr(shape, "shape_type", None) == MSO_SHAPE_TYPE.GROUP and hasattr(shape, "shapes"):
            for inner in shape.shapes:
                traverse_shape(inner)
            return

        # ÌÖçÏä§Ìä∏ ÌîÑÎ†àÏûÑ
        if getattr(shape, "has_text_frame", False) and shape.has_text_frame:
            tf = shape.text_frame
            process_paragraphs_block(tf.paragraphs, chinese_review_enabled=("Chinese" in target_lang))
            return

        # Ìëú
        if getattr(shape, "has_table", False) and shape.has_table:
            for row in shape.table.rows:
                for cell in row.cells:
                    if getattr(cell, "text_frame", None):
                        process_paragraphs_block(cell.text_frame.paragraphs, chinese_review_enabled=("Chinese" in target_lang))
            return

    for s_idx, slide in enumerate(pres.slides, start=1):
        print(f"‚ñ∂ Ïä¨ÎùºÏù¥Îìú {s_idx}/{slide_count}")
        for shape in slide.shapes:
            traverse_shape(shape)

    # ---------- [Ìè∞Ìä∏ Ïä§ÏºÄÏùº Ï†ÅÏö©] ----------
    def apply_font_scale(presentation, scale_percent: int):
        from pptx.util import Pt
        factor = max(1, scale_percent) / 100.0

        def scale_run(run):
            if run.font.size is not None:
                try:
                    run.font.size = Pt(run.font.size.pt * factor)
                except Exception:
                    pass

        def scale_paragraph(paragraph):
            # Î¨∏Îã® Î†àÎ≤® Ìè∞Ìä∏Í∞Ä ÏßÄÏ†ïÎêú Í≤ΩÏö∞ Ïä§ÏºÄÏùº
            if paragraph.font is not None and paragraph.font.size is not None:
                try:
                    paragraph.font.size = Pt(paragraph.font.size.pt * factor)
                except Exception:
                    pass
            # Í∞Å Îü∞ Ïä§ÏºÄÏùº
            for r in paragraph.runs:
                scale_run(r)

        def traverse_scale_shape(shape):
            if getattr(shape, "shape_type", None) == MSO_SHAPE_TYPE.GROUP and hasattr(shape, "shapes"):
                for inner in shape.shapes:
                    traverse_scale_shape(inner)
                return
            if getattr(shape, "has_text_frame", False) and shape.has_text_frame:
                for p in shape.text_frame.paragraphs:
                    scale_paragraph(p)
                return
            if getattr(shape, "has_table", False) and shape.has_table:
                for row in shape.table.rows:
                    for cell in row.cells:
                        if getattr(cell, "text_frame", None):
                            for p in cell.text_frame.paragraphs:
                                scale_paragraph(p)
                return

        if abs(factor - 1.0) < 1e-6:
            return
        for slide in presentation.slides:
            for shape in slide.shapes:
                traverse_scale_shape(shape)

    apply_font_scale(pres, font_scale_percent)

    folder = os.path.dirname(pptx_path)
    stem, ext = os.path.splitext(os.path.basename(pptx_path))
    
    # Ï§ëÍµ≠Ïñ¥ Î≤àÏó≠Ïùò Í≤ΩÏö∞ ÌÜ§ ÎåÄÏã† Ï§ëÍµ≠Ïñ¥ ÌÉÄÏûÖÏùÑ ÏÇ¨Ïö©
    if "Chinese" in target_lang:
        chinese_type = "Simplified" if "Simplified" in target_lang else "Traditional"
        outfile_name = f"{stem}_Chinese_{chinese_type}_AIÎ≤àÏó≠ÏôÑÎ£å{ext}"
    else:
        safe_tone = re.sub(r'[^0-9A-Za-zÍ∞Ä-Ìû£_()+-]', '', tone.replace(' ', ''))
        outfile_name = f"{stem}_{target_lang}_{safe_tone}_AIÎ≤àÏó≠ÏôÑÎ£å{ext}"
    
    outfile_path = os.path.join(folder, outfile_name)
    outfile_path = unique_path(outfile_path)

    print("-" * 60)
    print("üíæ Ï†ÄÏû• Ï§ë...")
    pres.save(outfile_path)
    print(f"‚úÖ Î≤àÏó≠ ÏôÑÎ£å! Ï†ÄÏû•Îêú ÌååÏùº: {outfile_path}")
    return outfile_path


def main():
    pptx_path = choose_pptx_with_dialog()
    if not pptx_path:
        print("‚ùå ÌååÏùºÏùÑ ÏÑ†ÌÉùÌïòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Ï¢ÖÎ£åÌï©ÎãàÎã§.")
        return

    target_lang = choose_language_with_window()
    if not target_lang:
        print("‚ùå Ïñ∏Ïñ¥Î•º ÏÑ†ÌÉùÌïòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Ï¢ÖÎ£åÌï©ÎãàÎã§.")
        return

    tone, use_deepseek = choose_tone_with_window(target_lang)
    if not tone:
        print("‚ùå ÌÜ§ÏùÑ ÏÑ†ÌÉùÌïòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Ï¢ÖÎ£åÌï©ÎãàÎã§.")
        return
    font_scale = choose_font_scale_window()
    translate_presentation(pptx_path, target_lang, tone, use_deepseek, font_scale_percent=font_scale)


if __name__ == "__main__":
    main()
